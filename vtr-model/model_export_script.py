"""
VTR Model Export Script
å°‡è¨“ç·´å¥½çš„PyTorchæ¨¡å‹å°å‡ºç‚ºC++å¯ç”¨çš„æ ¼å¼
"""

import torch
import json
import numpy as np
from sklearn.preprocessing import StandardScaler

def export_vtr_model(model, scaler, output_dir="./exported_model/"):
    """
    å°å‡ºVTRæ¨¡å‹åƒæ•¸ç‚ºC++å¯ç”¨æ ¼å¼
    
    Args:
        model: è¨“ç·´å¥½çš„PyTorchæ¨¡å‹
        scaler: è¨“ç·´æ™‚ä½¿ç”¨çš„StandardScaler
        output_dir: è¼¸å‡ºç›®éŒ„
    """
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. å°å‡ºStandardScaleråƒæ•¸
    scaler_params = {
        "mean": scaler.mean_.tolist(),
        "std": scaler.scale_.tolist(),  # sklearnä¸­scale_æ˜¯æ¨™æº–å·®
        "feature_count": len(scaler.mean_)
    }
    
    with open(f"{output_dir}/scaler_params.json", "w") as f:
        json.dump(scaler_params, f, indent=2)
    
    # 2. å°å‡ºç¥ç¶“ç¶²çµ¡æ¬Šé‡
    model.eval()
    model_params = {}
    
    # ç²å–æ¯å±¤çš„æ¬Šé‡å’Œåç½®
    layers = list(model.net.children())
    layer_idx = 0
    
    for i, layer in enumerate(layers):
        if isinstance(layer, torch.nn.Linear):
            # æ¬Šé‡çŸ©é™£ (è½‰ç½®ä»¥åŒ¹é…C++çš„çŸ©é™£ä¹˜æ³•é †åº)
            weight = layer.weight.detach().numpy()
            bias = layer.bias.detach().numpy()
            
            model_params[f"layer_{layer_idx}"] = {
                "weight": weight.tolist(),  # [output_dim, input_dim]
                "bias": bias.tolist(),
                "input_dim": weight.shape[1],
                "output_dim": weight.shape[0]
            }
            layer_idx += 1
    
    # 3. å°å‡ºæ¨¡å‹å…ƒæ•¸æ“š
    model_metadata = {
        "architecture": "MLP",
        "input_dim": 17,
        "hidden_dim": 64,
        "output_dim": 5,
        "num_layers": 3,
        "activation": "ReLU",
        "layer_count": layer_idx
    }
    
    model_params["metadata"] = model_metadata
    
    with open(f"{output_dir}/model_weights.json", "w") as f:
        json.dump(model_params, f, indent=2)
    
    # 4. å°å‡ºæ¸¬è©¦å‘é‡ï¼ˆç”¨æ–¼é©—è­‰ï¼‰
    test_input = np.random.randn(1, 17).astype(np.float32)
    test_input_scaled = scaler.transform(test_input)
    
    with torch.no_grad():
        test_output = model(torch.tensor(test_input_scaled, dtype=torch.float32))
    
    test_data = {
        "input_raw": test_input.tolist(),
        "input_scaled": test_input_scaled.tolist(),
        "expected_output": test_output.numpy().tolist()
    }
    
    with open(f"{output_dir}/test_vectors.json", "w") as f:
        json.dump(test_data, f, indent=2)
    
    print(f"âœ… æ¨¡å‹å°å‡ºå®Œæˆï¼")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print(f"ğŸ“„ æª”æ¡ˆ:")
    print(f"   - scaler_params.json: StandardScaleråƒæ•¸")
    print(f"   - model_weights.json: ç¥ç¶“ç¶²çµ¡æ¬Šé‡")
    print(f"   - test_vectors.json: æ¸¬è©¦å‘é‡")

# ä½¿ç”¨ç¯„ä¾‹ï¼š
if __name__ == "__main__":
    # å‡è¨­ä½ å·²ç¶“æœ‰è¨“ç·´å¥½çš„æ¨¡å‹å’Œscaler
    # model = your_trained_model
    # scaler = your_trained_scaler
    
    # export_vtr_model(model, scaler)
    
    print("è«‹åœ¨ä½ çš„ vtr_model.ipynb æœ€å¾ŒåŠ å…¥ä»¥ä¸‹ä»£ç¢¼ï¼š")
    print()
    print("# å°å‡ºæ¨¡å‹")
    print("exec(open('model_export_script.py').read())")
    print("export_vtr_model(model, scaler)")